{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_mining.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EYZPNnQnu1jP",
        "9jlAqoqmyc-8",
        "1-bAxSJRBiW-"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarp-u/Data-Mining/blob/main/data_mining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSD4ySwkRflE"
      },
      "source": [
        "## Business Understanding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdaXxGb1RtAs"
      },
      "source": [
        "Projenin amacı bu adımda tanımlanır.\r\n",
        "Projenin ana hedefinin ne olduğunu tüm proje paydaşlarıyla görüşüp akabinde proje sponsoru ile el sıkışarak doğru bir şekilde belirlenmelidir.\r\n",
        "Yanlış anlaşılma veya düzgün anlaşılmama gibi durumlarda ileride büyük sıkıntılar ortaya çıkar çünkü bu adım data mining işleminin temelidir.\r\n",
        "Bizim amacımız ise çalıştığımız bankadan almış olduğumuz veriler eşliğinde bankanın yeni ürünü olan BF1Kart'ı hangi müşterilere satabilecekleri konusunda bilgi veren verileri açığa çıkartmaktır. Bu işlemin sonucuna göre banka reklam hedef kitlesini vb şeylerini hayata geçirecektir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYZPNnQnu1jP"
      },
      "source": [
        "## Data Understanding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N6N_ZslRa_c"
      },
      "source": [
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "import numpy as np\r\n",
        "from matplotlib import pyplot as plt \r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "csv_url = ('https://raw.githubusercontent.com/sarp-u/csv/main/bank_marketing_adal_v1.0%20(1).csv')\r\n",
        "df = pd.read_csv(csv_url, sep= ';', decimal= ',')\r\n",
        "print(df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOu_qtBORcYE"
      },
      "source": [
        "Burada datayı analiz etmemiz için gerekli kütüphaneleri importladık. Daha sonrasında github'dan csv dosyamızı çekip df adlı variable'ın içine koyduk ve csv dosyamızın kaç sütun ve satırdan oluştuğna baktık"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xCOBtHZt8VL"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHf8oA9JuJ7m"
      },
      "source": [
        "İlk adımımız çalıştığımız datanın infosunu almak. Böylece Sütunlarımızı ve sütunların sahip olduğu değerlerin türlerini gözlemleriz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La0XpAuMudsk"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdK9emkouhKs"
      },
      "source": [
        "Sütun ve satır sayısını gözlemleme"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oorXTDkMBlmI"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Hov-mvmdkbh"
      },
      "source": [
        "Çalıştığımız datayı gözlemlemek ve içindeki değerlere bakmak için .head() fonksiyonunu kullandık"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBC90bhfxIrm"
      },
      "source": [
        "df.describe(include = 'all').transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDf7hAgaxPg5"
      },
      "source": [
        "Çalıştığımız veri hakkında daha iyi bilgi almak için bu adımı kullanırız. Böylelikle integer değerler için standart sapma, ortalama değer min ve max gibi değerleri kolaylıkla görebiliriz. String değerleri için ise en çok kullanılan şeyi ve sıklığı gibi şeylere ulaşabiliriz. Genel olarak ise hangi değer data setimizde kaç kere kullanılmış vb şeylere ulaşırız."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBRgOT2nu_2t"
      },
      "source": [
        "df.sort_values(by = ['Alter','Kontostand'], ascending = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LCtyiZpvRyE"
      },
      "source": [
        "Artan sırayla yaş ve bankadaki para miktarına göre sıralama"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy4BZ34wxonR"
      },
      "source": [
        "duplicate_rows_data = df[df.duplicated()]\r\n",
        "duplicate_rows_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFLgqOI0x6ja"
      },
      "source": [
        "df = df.drop_duplicates()\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFYqAgk3yOou"
      },
      "source": [
        "Tekrarlanan satırları bulup, bu satırları çıkarmamız gerekli"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp1ROaGJyeKX"
      },
      "source": [
        "df.isnull().values.any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83PQ9eGqyjz9"
      },
      "source": [
        "Verilerimizin içerisinde herhangi bir şekilde boş bir kısım olup olmadığına baktık eğer false dönerse herhangi bir şekilde nan veya null değeri olmadığını görürüz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Tw-P0LlystX"
      },
      "source": [
        "#df.dropna(inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6gMxyIxytRB"
      },
      "source": [
        "Yukarıdaki kodda gördüğümüz üzere kodumuzda herhangi bir şekilde null veya NaN değerinde herhangi bir şey bulunmamakta. Ancak bulunduğu takdirde bu verileri işleme katamıyoruz ve daha sonrasında sıkıntılar çıkarabiliyor. Bu yüzden yapılabilecek yöntemlerden birisi bu değerleri düşürerek işleme almamaktır."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryVB4Nobyth1"
      },
      "source": [
        "#df['Alter'].replace(np.NaN,df['Alter'].mean()).tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j73S2X2Dytr-"
      },
      "source": [
        "Yine varsayımsal olarak Yaş sütunumuzda eksik değerler olduğunu varsayalım. Bir diğer yaklaşım ise bu değerleri silmek yerine yerine yeni değerler atamaktır. Bu durumda yapılabilecek en iyi yaklaşım ortalama, medyan veya mod değerlerinden birisini seçmektir. Burada da yaptığımız işlem NaN değerindeki satırları yaş ortalaması ile değiştirmektir."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQHDssKVkPHv"
      },
      "source": [
        "berufs = df['Beruf'].unique()\r\n",
        "data = df['Beruf'].value_counts()\r\n",
        "fig = plt.figure(figsize =(12, 7)) \r\n",
        "plt.pie(data, autopct='%1.1f%%', labels = berufs)\r\n",
        "plt.show()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KShDn0Zkmnul"
      },
      "source": [
        "Berufs değerimizin içerisine bu data setteki her bir farklı iş değerini atıyoruz. Data değerimizde ise her bir meslekte kaç kişinin olduğuna ulaşırız. Daha sonrasında elde ettiğimiz bu verileri pasta grafiğini çizecek olan komutumuzu içersine yerleştirdiğimizde de gösterilen sonuç ortaya çıkar. Bu pasta grafiğine bakarak banka hesabı olan kişilerin çoğunluğunun hangi meslek grubundan olduğunu kolayca görebiliriz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_Vn7c3ioXV3"
      },
      "source": [
        "familienstand = df['Familienstand'].unique()\r\n",
        "data = df['Familienstand'].value_counts()\r\n",
        "y_pos = np.arange(len(familienstand))\r\n",
        "plt.bar(y_pos, data, align='center', alpha=0.5, width= 0.4, color ='#540c8a')\r\n",
        "plt.xticks(y_pos, familienstand)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvFOF_2Nsk27"
      },
      "source": [
        "Öncelikle grafiğini çizeceğimiz verinin hangi değerler olduğunu ve kaçar tane olduğunu bulmamız gerekiyor burada familienstand ve data değerleri ile birisinde hangi değerler olduğunu diğerinde bu değerlerden kaçar tane olduğunu görüyoruz. y_pos değerimizde de değerlerimizi sıralıyoruz. plt.bar kısmında ise bar yani sütun grafiğimizin değerlerini giriyoruz ve bunları büyükten küçüğe sıralıyor. .xticks kısmında hangi sütunun altına hangi değerin geleceği belirlenip yazılıyor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0I1ubU_vWc6"
      },
      "source": [
        "plt.hist(df['Alter'], color = 'green', edgecolor = 'black',bins = 30)\r\n",
        "plt.title('Age Distribution')\r\n",
        "plt.xlabel('Age')\r\n",
        "plt.ylabel('Population')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNMzaVmMmmNn"
      },
      "source": [
        "Yaş dağılımına ait histogramı çiziyoruz. Bu sayede bankamızdaki müşterilerin hangi yaş aralığında daha sık olduğunu görebiliyoruz. plt.hist fonksiyonu ile histogram çizeceğimizi belirtiyoruz, içerisindeki değerler ise anlaşılır sadece bins değeri önemli o da bu histogramın kaç parçaya bölüneceğini belirliyor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TESJ9vj7o0WX"
      },
      "source": [
        "sns.distplot(df['Kontostand'], hist=True, kde=True, \r\n",
        "             bins=50, color = 'teal', \r\n",
        "             hist_kws={'edgecolor':'black'},\r\n",
        "             kde_kws={'linewidth': 3})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gpKM_Wbqkfa"
      },
      "source": [
        "Burada da banka hesabındaki para miktarının yoğunluğunu gösteren grafiği çiziyoruz. .distplot ise yoğunluk grafiğini çiziyoruz. Daha düzgün ve gerçekçi olması adına bins değerimizi ne kadar büyük yaparsak o kadar iyi aslında. hist = True olduğunda sütun grafiklerini çiziyor, kde = True olduğunda da üzerindeki çizgi grafiğini çiziyor. Grafiğin renk, kalın vb özelleriklerine ulaşabilmemiz için hist ve kde değerlerini kullanmamız gerekiyor.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TltAhS_dtrB2"
      },
      "source": [
        "df[(df['Label'] == 1) & (df['Alter'] < 30) & (df['Ausbildung'] == 'Hochschulabschluss') & (df['Kontostand'] > 1000)].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WTwykfswqtI"
      },
      "source": [
        "Banka veya müşteri tarafından verilen spesifik kısıtlamara göre elimizdeki datalarla oynamamız çok basit. Sadece 1 satır kod ile verilen kısıtlamalara göre yeni bir data set oluşturabiliriz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV_Fv13e0iqz"
      },
      "source": [
        "import seaborn as sns\r\n",
        "corr = df.corr()\r\n",
        "plt.figure(figsize=(12,9))\r\n",
        "sns.heatmap(corr, \r\n",
        "            xticklabels=corr.columns.values,\r\n",
        "            yticklabels=corr.columns.values,\r\n",
        "            linewidth= 0.2,\r\n",
        "            linecolor = 'black',\r\n",
        "            annot = True,\r\n",
        "            cmap=\"YlGnBu\",\r\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9hW5fcc2zNQ"
      },
      "source": [
        "Korelasyon ilişikisini gösterecek olursak. annot = True => her kare üzerindeki değerleri yazar, cmap matris'in rengi. Data setimizdeki 7 adet değerinin birbiri ile dolaylı ya da dolaylı olmadan oluşan ilişkisini gösteren grafik"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aujo_Rh93gFi"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(20,6))\r\n",
        "ax.scatter(df['Kontostand'], df['Alter'])\r\n",
        "ax.set_xlabel('Kontostand')\r\n",
        "ax.set_ylabel('Alter')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3Ogzj164pCt"
      },
      "source": [
        "Data setimizdeki 2 farklı değer olan yaş ve banka hesabında bulunan para miktarı için çizilmiş Scatter plot yani Serpilme diyagramı"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jlAqoqmyc-8"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMwNPPfyybO5"
      },
      "source": [
        "df.iloc[:5].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh0B2ZJxy-Mk"
      },
      "source": [
        ".iloc sayesinde n'den m'ye kadar giden değerleri kolaylıkla inceleyebiliriz. Elimizdeki değerlerle çalışmak için numerik verilere sahip olmamız gerekli ancak gördüğümüz gibi Beruf, Familienstand, Ausbildung string türünde verilere sahip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_wdlHA_z5La"
      },
      "source": [
        "label_encoder = LabelEncoder()\r\n",
        "df['Beruf'] = label_encoder.fit_transform(df['Beruf'])\r\n",
        "df['Familienstand'] = label_encoder.fit_transform(df['Familienstand'])\r\n",
        "df['Ausbildung'] = label_encoder.fit_transform(df['Ausbildung'])\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHSvKjr94jDT"
      },
      "source": [
        "String türünde olan 3 adet sütunu da integer'a çevirdiğimize göre veri inceleme işlemine bir adım daha yaklaşıyoruz. Lakin bu işlem sonunda şöyle bir sorun oluşuyor. Farklı türde işler, medeni durumlar veya öğrenim durumları için farklı integer değerleri atadı. Örneğin Familienstandda verheiratet için 2 ledig için 1 değerini atadı. Matematiksel olarak 2>1 ama bu evli bir bireyin değerinin bekar bir insandan daha yüksek olduğu anlamına gelmiyor ama bilgisayar bunu bilmiyor, o yüzden dummy variableları kullanmamız gerekiyor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rlL5tu15zs_"
      },
      "source": [
        "dummy = pd.get_dummies(df['Beruf']).astype(int)\r\n",
        "dummy2 = pd.get_dummies(df['Familienstand'])\r\n",
        "dummy3 = pd.get_dummies(df['Ausbildung'])\r\n",
        "dummy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnwLKDYL7Olq"
      },
      "source": [
        "Yukarıda belirtilen sebepten dolayı bir şekilde bizlere verilmiş olan integerlarla oynamamız gerekiyor. Burada da yardımımıza dummy variable yetişiyor. Yapılan işlem kısaca Sütundaki kişi hangi değerdeki stringe sahipse o mesleği/medeni halini/eğitimi 1 geri kalan kısımlara 0 değerini atıyor. Bu işlem sayesinde bir mesleğin diğerine üstünlüğü vb gibi durumlar ortadan kalkıyor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRwaTAZr6Gq2"
      },
      "source": [
        "df = pd.concat([df,dummy, dummy2, dummy3], axis = 1)\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7_2iteu8Isj"
      },
      "source": [
        "Burada ise oluşturduğum 3 adet dummy data setini kullanmakta olduğumuz data sete ekliyoruz. Belirtilen sütunları istediğimiz şekle dönüştürdüğümüze göre bu sütunlardan kurtulmamız gerekiyor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIineF1B83LA"
      },
      "source": [
        "df.drop(['Beruf','Familienstand','Ausbildung'], axis =1 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abAvrPwvfRT4"
      },
      "source": [
        "Bu 3 değer yerine 1 ve 0 içeren sütunları ekledikten sonra bu değerler ile işimiz bitti."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xCvjXfNBnZj"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X = df.drop(['Label','Beruf','Familienstand','Ausbildung'], axis = 1)\r\n",
        "y = df['Label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJNsm0BMgEM7"
      },
      "source": [
        "Data setimizi çalıştıracağımız x ve y değerlerine ihtiyacımız var. Bağımsız değişkenimiz yani hedef değerimiz label değeri olduğu için bunu droplamamız lazım.(Diğer üçlü üstte droplanıyor ama kayıt edilmediği için burada da droplamamız lazım)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ9jPaCNBpsf"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj2ayx5ugmAI"
      },
      "source": [
        "X_test algoritmaya sokup öğreteceğimiz kısım, X_train bu algoritmanın üzerinde çalışacağı kısmı, y_train X_train ile alakalı bağımlı değişkenlerin olduğu kısım, y_test de X_test ile alakalı bağımlı değişkenlerin olduğu kısım. test_size= 0 ve 1 arasında 1 değer alır aldığı değere göre bu data set'in % kaçı ile çalışacağını belirler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IK7_HtfBr5X"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7caT6jUiWJj"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9my58xqrkTvj"
      },
      "source": [
        "Son Adım olarak ise Feature Scalling yani Özellik Ölçeklendirme yapmamız lazım. Tablodan da görüldüğü üzere Yaş ve Bankadaki para arasında ölçek farkı var. Örneğin Yaşlar arasında 34 - 37, Para arasında 171 - 681 ciddi farklar var. Bir değer diğer değeri domine edebilir bunun önüne geçmemiz lazım. Bu algoritmamızda sıkıntı yaratıcak çünkü çoğu makine öğrenmesi algoritması öklid mesafesi kullanılır. Bu değerleri tekrar ölçeklendirmemiz lazım"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkXQEK9_lcp7"
      },
      "source": [
        "![picture](https://hackernoon.com/hn-images/1*Ud6qCIDqDEn5k_q3YTaP1g.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5ru6OQOBtbM"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWr2ZUFkBva_"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6F_FI5mBxM1"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSQMpDw5h8s5"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\r\n",
        "standard_X = StandardScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-VG0KJxiMtT"
      },
      "source": [
        "X_train = standard_X.fit_transform(X_train)\r\n",
        "X_test = standard_X.fit_transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc9hIIrCkOM6"
      },
      "source": [
        "Wikipedia'dan da baktığımız da 3 adet yeniden ölçeklendirme var \r\n",
        "- min-max normalization\r\n",
        "- mean normalization\r\n",
        "- standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QLLu2L9mS5s"
      },
      "source": [
        "![picture](https://www.oreilly.com/library/view/hands-on-machine-learning/9781788393485/assets/7a9d8cb9-10f7-43b5-b52f-865fbbb0b69e.png)\r\n",
        "\r\n",
        "Xscale = yeni x değeri\r\n",
        "x = tablodaki değerimiz\r\n",
        "mean = x değerinin ortalaması\r\n",
        "sd = standart sapma\r\n",
        "Bu formülü bu işlemde her bir değer için uygular"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBwzG7hzjyyi"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atrlNY8pj4_o"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXjzYcnsmulu"
      },
      "source": [
        "Görüldüğü üzere datamızın sayısında herhangi bir değişme olmadı ama değerlerimize Standardizasyon uygulandı böylece daha doğru bir oranda sonuç elde edebileceğiz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcVjfE89rpWH"
      },
      "source": [
        "## Modelling\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUpEr4Q2BzN3"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "model_rf = RandomForestClassifier(random_state= 4711, n_estimators=200,max_depth=4)\r\n",
        "model_rf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9FUTUijZXUG"
      },
      "source": [
        "Bu adımda modellemede kullanacağımız algoritma olan random forest algoritmasını çağırıyoruz. random_state = datayı okumaya 1. satırdan değil de içine atanan satırdan başlanmasını söylüyor, n_estimators= algoritmamızdaki ağaç sayısını yani gözlemci sayısını belirler, max_depth search tree'nin dallanmasını gösteren parametre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZuMu3WmB2pT"
      },
      "source": [
        "model_rf.score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKLGfe0yZ2Dm"
      },
      "source": [
        "Verilen modelimizin işleme sokulduktan sonra % kaç başarı ile çalıştığını gösterir. Accuracy yani tutarlılığımızı gösteriyor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUtKhLDvB3KP"
      },
      "source": [
        "y_predicted = model_rf.predict(X_test)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ybvl1xvGZ7Lk"
      },
      "source": [
        "Bu adımda aslında çıkması gereken sonucu y_predicted yani önceden beklenen değer içine atıyoruz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYORVBogB5Rs"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "cm = confusion_matrix(y_test, y_predicted)\r\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgEgKAZTaETU"
      },
      "source": [
        "Bu adımda hata matrisimizin beklenen ve alınan sonucu karşılaştırmasını görüyoruz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ro2iqkQB7e6"
      },
      "source": [
        "%matplotlib inline\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sn\r\n",
        "plt.figure(figsize=(10,7))\r\n",
        "sn.heatmap(cm, annot=True)\r\n",
        "plt.xlabel('Predicted')\r\n",
        "plt.ylabel('Truth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZtdWuCsaTH8"
      },
      "source": [
        "Bir önceki adımda çizmiş olduğumuz matrisin görselleştirilmiş hali"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R31MGEVTlKND"
      },
      "source": [
        "Modelling işlemi önemli bir adım, bu sayede istenilen işe en uygun modelin hangisi olduğu ve hangisinin daha tutarlı olup olmadığını görebiliriz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyZT4dW5eG1N"
      },
      "source": [
        "from sklearn.svm import SVC\r\n",
        "model_SVC = SVC(kernel = 'rbf', random_state=4711)\r\n",
        "model_SVC.fit(X_train, y_train)\r\n",
        "\r\n",
        "y_pred_svm = model_SVC.decision_function(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7rbk-RomA6n"
      },
      "source": [
        "Destek vektör makineleri, sınıflandırma ve regresyon analizi için verileri analiz eden ilişkili öğrenme algoritmalarına sahip denetimli öğrenme modelleridir. Burada yaptığımız işlem ise bir başka modellemeyi bize verilen datasete uygunluğunu ölçmektir. y_pred_svm'de yaptığımız şey X_testteki verilerinin her birisininin decision_function aracılığı ile yapmış olduğumuz düzlemdeki verilere olan uzaklığının tespitidir."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfsJMsRceaex"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\r\n",
        "model_logistic = LogisticRegression()\r\n",
        "model_logistic.fit(X_train, y_train)\r\n",
        "\r\n",
        "y_pred_logistic = model_logistic.decision_function(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xe-nQGQAnAXn"
      },
      "source": [
        "Yukarıda yaptığımız işlemin aynısını bir diğer modelleme biçimi olan Lojistik Regresyon için uyguluyoruz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdBg4d2tfikj"
      },
      "source": [
        "from sklearn.metrics import roc_curve, auc\r\n",
        "\r\n",
        "logistic_fpr, logistic_tpr, treshold = roc_curve(y_test, y_pred_logistic)\r\n",
        "auc_logistic = auc(logistic_fpr, logistic_tpr)\r\n",
        "\r\n",
        "svm_fpr, svm_tpr, treshold = roc_curve(y_test, y_pred_svm)\r\n",
        "auc_svm = auc(svm_fpr, svm_tpr)\r\n",
        "\r\n",
        "plt.figure(figsize=(6,6), dpi=100)\r\n",
        "plt.plot(svm_fpr, svm_tpr, linestyle='-', label= 'SVM (auc = %0.4f)' %auc_svm )\r\n",
        "plt.plot(logistic_fpr, logistic_tpr, marker='.', label='Logistic (auc = %0.4f)' % auc_logistic)\r\n",
        "\r\n",
        "plt.xlabel('FPR')\r\n",
        "plt.ylabel('TPR')\r\n",
        "\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf-QlL4DnJWl"
      },
      "source": [
        "TPR doğru şekilde tanımlanan gerçek pozitiflerin yüzdesini ölçmek için kullanılır.\r\n",
        "FPR belirli bir test için boş hipotezin yanlış bir şekilde reddedilme olasılığıdır.\r\n",
        "Treshold dediğimiz de belirlenilen bir değerde bu değerin altında veya üstünde olması durumuna göre sınıflandırma yapılabilir.\r\n",
        "Çizdğimiz ROC grafiği kısaca her bir trashold değeri için oluşturulan confusion matrix değerine denk gelir\r\n",
        "AUC değeri çizilen grafiğin altında kalan alana tekabül eder. Yani çizilen grafiğimiz ne kadar doğruysa alan dolayısıyla auc değerimiz büyür aynı şey tam tersi için de geçerlidir auc değerimiz ne kadar büyükse çizdiğimiz grafik o kadar doğrudur diyebiliriz.\r\n",
        "ilk adımda bu 2 değerin belirlenmesi için elde ettiğimiz ve gerçek olan 2 değerin karşılaştırması ile başlarız.\r\n",
        "Diğer adımda yapılan işlem ise bu çizdiğimiz grafiğin altında kalan alanı hesaplama işlemidir. Sonuç ne kadar büyükse yanıt o kadar doğrudur\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCnmW4f4wKPW"
      },
      "source": [
        "model_rf.score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrAeR0lwwO3z"
      },
      "source": [
        "auc_logistic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PQ5Q97ywUpk"
      },
      "source": [
        "auc_svm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwoU6xVrxSYe"
      },
      "source": [
        "Verilen 3 adet modellemeye göre en başarılı modellemenin SVM algoritması, en başarısız algoritmanın ise random forest olduğunu görürüz. Bu yüzden SVM algoritması ile devam etmemiz istenen sonucu daha iyi yakalayabileceğimizi gösteriyor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61I8LU-q7cxj"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHo9-6dKOuPy"
      },
      "source": [
        "Modelling kısmında en verimli algoritmamız SVM algoritması çıkmıştı. Bu algoritmada, her bir veri maddesini belirli bir koordinatın değeri olan her özelliğin değeri ile birlikte n-boyutlu boşluğa bir nokta olarak çizilir. Ardından, iki sınıftan oldukça iyi ayrım yapan hiper-düzlemi bularak sınıflandırma gerçekleştirilir. 2 Boyutlu düzlemde ayrımı yapan şey vektör 3 boyutlu da düzlem n boyutlu da hiper - düzlemdir. 2 ve 3 boyutlu düzlemde ayrımları çizmek görsel olarak mümkünken n boyutlu da ancak matematiksel olarak tasvir edebiliriz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqBN1F7JBBJv"
      },
      "source": [
        "df0 = df.loc[df['Label'] == 0]\r\n",
        "df1 = df.loc[df['Label'] == 1]\r\n",
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8IzX6MzPQEz"
      },
      "source": [
        "Burada yaptığımız işlem sonucumuz yani target değerimizin 1 ve 0 olduğu durumlardaki her bir değeri düzleme yerleştirmek ve yerleştirdiğimiz bu verileri en başarılı şekilde bölmektir."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ofwkNoxHE4P"
      },
      "source": [
        "%matplotlib inline\r\n",
        "plt.xlabel('Alter')\r\n",
        "plt.ylabel('Kontostand')\r\n",
        "plt.scatter(df0['Alter'], df0['Kontostand'], color = 'green', marker='+')\r\n",
        "plt.scatter(df1['Alter'], df1['Kontostand'], color = 'blue', marker='.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGkSxwuhH4J0"
      },
      "source": [
        "plt.xlabel('Alter')\r\n",
        "plt.ylabel('Dauer')\r\n",
        "plt.scatter(df0['Alter'], df0['Dauer'], color = 'green', marker='+')\r\n",
        "plt.scatter(df1['Alter'], df1['Dauer'], color = 'blue', marker='.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miKF4msKPhbY"
      },
      "source": [
        "Yukarıdaki 2 örnekte görüldüğü üzere verilerimiz 2 boyutlu düzlem üzerine yerleştirilmiştir. Elimizde çok fazla veri bulunduğu için şuanda gözle görülebilir bir ayrım yapmamız çok zor. Lakin x ve y boyutuna ekstra olarak belki z boyutu da eklenirse ayrımı yapmak kolaylaşabilir."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82s0QTBMINtz"
      },
      "source": [
        "# X = df.drop(['Label','Beruf','Familienstand','Ausbildung'], axis = 1)\r\n",
        "# y = df['Label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5olpYNzIm_W"
      },
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shymY-PEPzkD"
      },
      "source": [
        "Aslında yukarıda yapılan işlemler bu iki işlem ile sınırlı değildir ama zaten yapılacak olan işlemler preprocessing kısmında yapıldığı için tekrar buraya yazmak anlamsız olur."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZy2fZTSIpsf"
      },
      "source": [
        "from sklearn.svm import SVC\r\n",
        "model = SVC()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU9s4uEsIvV9"
      },
      "source": [
        "model.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0PLvfqKI2ub"
      },
      "source": [
        "model.score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0chR0wpMKFRZ"
      },
      "source": [
        "y_predicted = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op86bvKyQnm4"
      },
      "source": [
        "Çalışacağımız algoritmaya ait kütüphaneyi importlamamız gerekli. Bu kütüphaneyi importladıktan sonra random forestta kullandığımız gibi değerlerimizi gerekli fonksiyonların içine yerleştiriyoruz.\r\n",
        "model.score'a baktığımızda ise random forest algoritmasından daha iyi bir sonuç elde ettiğimizi görüyoruz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDrSlJxyKIZ3"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "cm2 = confusion_matrix(y_test, y_predicted)\r\n",
        "cm2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNX0ocHYKL6I"
      },
      "source": [
        "%matplotlib inline\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sn\r\n",
        "plt.figure(figsize=(10,7))\r\n",
        "sn.heatmap(cm, annot=True)\r\n",
        "plt.xlabel('Predicted')\r\n",
        "plt.ylabel('Truth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0r7IK9VRAr_"
      },
      "source": [
        "Yine oluşturmuş olduğumuz confusion matrix'i burada görebiliriz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-bAxSJRBiW-"
      },
      "source": [
        "## Deployment\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFeCzDeaBmgO"
      },
      "source": [
        "Bu adımda, model, veri kümesinin kapsamı dışındaki yeni verilerde ve yeni paydaşlar tarafından kullanılır. Bu aşamadaki yeni etkileşimler, veri kümesi ve modeli için yeni değişkenleri ve ihtiyaçları ortaya çıkarabilir. Bu sebeple en başta belirlenmiş olan iş ihtiyaçlarında değişiklik ihtiyacı ortaya çıkabilir ve süreç değişiklik ihtiyaçları sebebi ile yeniden başlayabilir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhlJyLw4ROhz"
      },
      "source": [
        "Aynı amaca hizmet eden elimizdekinden farklı verilere ihtiyacımız var lakin şuanda bizde bu veriler yok"
      ]
    }
  ]
}